{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "import midi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import keras\n",
    "import warnings\n",
    "import pickle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, TimeDistributed, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidiTokenizer():\n",
    "    def __init__(self, filepath, padding=True):\n",
    "        '''\n",
    "        filepath: path to MIDI file\n",
    "        padding: whether or not to pad time series data in case of polyphony\n",
    "        self.mid: python-midi parsing of MIDI file\n",
    "        self.format: format of MIDI file (0, 1, 2)\n",
    "        self.tick_relative: whether event ticks are recorded relative to other\n",
    "            events or absolutely\n",
    "        '''\n",
    "        self.mid = midi.read_midifile(filepath)\n",
    "        self.format = self.mid.format\n",
    "        self.tick_relative = self.mid.tick_relative\n",
    "        self.padding = padding\n",
    "        \n",
    "        self.event_data = {i: [] for i in range(17)}\n",
    "        self.time_series_data = {}\n",
    "        \n",
    "        if self.format == 0:         # one midi track\n",
    "            self.parse_track([mid], self.tick_relative)\n",
    "        elif self.format == 1:       # multiple midi tracks\n",
    "            for track in self.mid:\n",
    "                self.parse_track(track, self.tick_relative)\n",
    "                \n",
    "        for i in self.event_data.keys():\n",
    "            self.event_data[i] = pd.DataFrame(\n",
    "                self.event_data[i], columns=['start', 'duration', 'pitch', 'velocity'])\n",
    "            \n",
    "        self.gen_time_series_data()\n",
    "                            \n",
    "    def parse_track(self, track, tick_relative=True):        \n",
    "        tick = 0\n",
    "        pitch_data = {}\n",
    "        \n",
    "        for event in track:\n",
    "            if type(event) != midi.NoteOnEvent and type(event) != midi.NoteOffEvent:\n",
    "                # if event does not correspond to a note, skip event\n",
    "                continue\n",
    "\n",
    "            tick = (tick + event.tick) if tick_relative else event.tick\n",
    "            \n",
    "            if event.velocity != 0 and type(event) != midi.NoteOffEvent:\n",
    "                # note on\n",
    "                datum = [tick, None, event.pitch, event.velocity]\n",
    "                self.event_data[event.channel].append(datum)\n",
    "                try:\n",
    "                    if pitch_data[event.pitch][-1][1] == None:\n",
    "                        pitch_data[event.pitch][-1][1] = tick\n",
    "                        \n",
    "                    pitch_data[event.pitch].append(datum)\n",
    "                except KeyError:\n",
    "                    pitch_data[event.pitch] = [datum]\n",
    "            else:\n",
    "                # note off\n",
    "                pitch_data[event.pitch][-1][1] = tick - self.event_data[event.channel][-1][0]\n",
    "                                \n",
    "    def gen_time_series_data(self):\n",
    "        for channel, parsed_track in self.event_data.items():\n",
    "            if parsed_track.shape[0] == 0:\n",
    "                continue\n",
    "            \n",
    "            ticks = parsed_track[['start', 'duration']].values\n",
    "            max_tick = max(map(lambda x:np.sum(x), ticks)) + 1\n",
    "            \n",
    "            self.time_series_data[channel] = [[] for _ in range(max_tick)]\n",
    "            \n",
    "            for _, event in parsed_track.iterrows():\n",
    "                start, duration, pitch, velocity = event.values\n",
    "                end = start + duration\n",
    "                note = (pitch, velocity)\n",
    "                                \n",
    "                self.time_series_data[channel][start].append(note)\n",
    "                self.time_series_data[channel][end].append(note)\n",
    "                \n",
    "            activated_notes = set([])\n",
    "            \n",
    "            for i, notes in enumerate(self.time_series_data[channel]):\n",
    "                for note in notes:\n",
    "                    if note not in activated_notes:\n",
    "                        activated_notes.add(note)\n",
    "                    else:\n",
    "                        activated_notes.remove(note)\n",
    "                \n",
    "                self.time_series_data[channel][i] = list(activated_notes)\n",
    "              \n",
    "            if self.padding:\n",
    "                self.time_series_data[channel] = \\\n",
    "                    keras.preprocessing.sequence.pad_sequences(self.time_series_data[channel])\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mt = MidiTokenizer('data/big_poppa/BigPoppa.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "midi.Track(\\\n",
       "  [midi.KeySignatureEvent(tick=0, data=[0, 0]),\n",
       "   midi.SmpteOffsetEvent(tick=0, data=[96, 0, 0, 0, 0]),\n",
       "   midi.SetTempoEvent(tick=0, data=[10, 230, 45]),\n",
       "   midi.TimeSignatureEvent(tick=0, data=[4, 2, 24, 8]),\n",
       "   midi.EndOfTrackEvent(tick=0, data=[])])"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.mid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, timestep):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)-timestep-1):\n",
    "        X.append(np.array([data[i:(i+timestep)]]))\n",
    "        y.append(np.array([data[(i+timestep)]]))\n",
    "        \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    return X.reshape(*[_ for _ in X.shape if _ != 1]), \\\n",
    "           y.reshape(*[_ for _ in y.shape if _ != 1])\n",
    "\n",
    "def cantor_pair(k1, k2):\n",
    "    return int((k1+k2)*(k1+k2+1)/2+k2)\n",
    "\n",
    "def cantor_unpair(z):\n",
    "    w = int((np.sqrt(8*z+1)-1)/2)\n",
    "    t = (w**2+w)/2\n",
    "    y = int(z-t)\n",
    "    x = int(w-y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, X, train_test_split=0.8, epochs=100, batch_size=10, lstm_units=128, timestep=32):\n",
    "        self.X = X\n",
    "        self.split = int(self.X.shape[0]*train_test_split)\n",
    "        self.X_train, self.X_test = self.X[:self.split], self.X[self.split:]\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm_units = lstm_units\n",
    "        self.timestep = timestep\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scale_data()\n",
    "        \n",
    "        self.model = Sequential()\n",
    "        self.model.add(\n",
    "            LSTM(self.lstm_units, input_shape=(\n",
    "                self.timestep, self.X_train_processed.shape[-1]\n",
    "            ), activation='relu')\n",
    "        )\n",
    "        self.model.add(Dense(self.X_train_processed.shape[-1]))\n",
    "        self.model.compile(optimizer='adamax', loss='mse', metrics=['accuracy'])\n",
    "        \n",
    "    def flatten_data(self):\n",
    "        self.X_train_flattened = np.apply_along_axis(lambda x:x[1], 2, self.X_train)\n",
    "        self.X_test_flattened = np.apply_along_axis(lambda x:x[1], 2, self.X_test)\n",
    "        \n",
    "    def scale_data(self):\n",
    "        self.flatten_data()\n",
    "        self.scaler.fit(self.X_train_flattened)\n",
    "        self.X_train_scaled = self.scaler.transform(self.X_train_flattened)\n",
    "        self.X_test_scaled = self.scaler.transform(self.X_test_flattened)\n",
    "        \n",
    "        self.X_train_processed, self.y_train_processed = \\\n",
    "            process_data(self.X_train_scaled, self.timestep)\n",
    "        self.X_test_processed, self.y_test_processed = \\\n",
    "            process_data(self.X_test_scaled, self.timestep)\n",
    "        \n",
    "    def train(self, verbose=0):\n",
    "        history = self.model.fit(self.X_train_processed, self.y_train_processed,\n",
    "                                 batch_size=self.batch_size, epochs=self.epochs)\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def evaluate(self):\n",
    "        keras.evaluate(x=self.y_test_processed,\n",
    "                       y=self.model.predict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(mt.time_series_data[0], epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "14655/14655 [==============================] - 61s 4ms/step - loss: 103.3263 - acc: 0.9376\n",
      "Epoch 2/5\n",
      "14655/14655 [==============================] - 65s 4ms/step - loss: 0.0391 - acc: 0.9464\n",
      "Epoch 3/5\n",
      "14655/14655 [==============================] - 60s 4ms/step - loss: 0.0171 - acc: 0.9750\n",
      "Epoch 4/5\n",
      "14655/14655 [==============================] - 59s 4ms/step - loss: 0.0110 - acc: 0.9849\n",
      "Epoch 5/5\n",
      "14655/14655 [==============================] - 58s 4ms/step - loss: 0.0082 - acc: 0.9859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14124d710>"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.train(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1058648028537323"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(rnn.scaler.inverse_transform(rnn.y_test_processed),\n",
    "                   rnn.scaler.inverse_transform(\n",
    "                       rnn.model.predict(rnn.X_test_processed)\n",
    "                   ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3640/3640 [==============================] - 1s 410us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.010141453635063314, 0.9648351648351648]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.model.evaluate(rnn.X_test_processed, rnn.y_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rnn.scaler.inverse_transform(rnn.model.predict(rnn.X_train_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_map(x):\n",
    "    if x < 0:\n",
    "        return 0\n",
    "    elif x > 127:\n",
    "        return 0\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_map = np.vectorize(note_map)\n",
    "pred = note_map(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = midi.Pattern()\n",
    "track = midi.Track()\n",
    "pattern.append(track)\n",
    "track.append(midi.PortEvent(tick=0, data=[0]))\n",
    "track.append(midi.TrackNameEvent(tick=0, text='Thank you Kanye, very cool!'))\n",
    "track.append(midi.ProgramChangeEvent(tick=0, channel=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "track2 = midi.Track()\n",
    "\n",
    "pred = rnn.scaler.inverse_transform(rnn.y_train_processed).astype(int)\n",
    "prev = []\n",
    "\n",
    "for tick, note_arr in enumerate(pred[:-1]):\n",
    "    for note in note_arr:\n",
    "        if note == 0: continue\n",
    "        \n",
    "        if note in prev:\n",
    "            if note not in pred[tick+1]:\n",
    "                track2.append(midi.NoteOnEvent(tick=tick, channel=10, data=[note, 0]))\n",
    "        else:\n",
    "            track2.append(midi.NoteOnEvent(tick=tick, channel=10, data=[note, 60]))\n",
    "            \n",
    "    prev = note_arr\n",
    "    \n",
    "for i, event in reversed(list(enumerate(track2))):\n",
    "    if i == 0:\n",
    "        continue\n",
    "        \n",
    "    event.tick = (event.tick - track2[i-1].tick)\n",
    "    \n",
    "pattern.append(track2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi.write_midifile(\"test.mid\", pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rnn.scaler.inverse_transform(rnn.model.predict(rnn.X_train_processed)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_d_convert(datum):\n",
    "    return datum.reshape(1, *datum.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "def babl(model, length, seed):\n",
    "    X, Y = copy.deepcopy(seed), []\n",
    "    init = model.predict(one_d_convert(X))\n",
    "    \n",
    "    for i in range(length):\n",
    "        y = rnn.model.predict(one_d_convert(X))\n",
    "        Y.append(y[0])\n",
    "        X = np.concatenate((X[1:], y), axis=0)\n",
    "\n",
    "    return np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = babl(rnn.model, 32, rnn.X_test_processed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pred', 'rb') as f:\n",
    "    pred = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_env",
   "language": "python",
   "name": "keras_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
